fastapi
fastapi_utils
pydantic
uvicorn
python-multipart
aiofiles
scipy
pandas
pypdf
torch>=1.7.1
faiss-cpu
tokenizers>=0.11.3
sentencepiece>=0.1.94
rouge-score>=0.0.4
sacrebleu>=1.5.1
numpy>=1.19.5
protobuf>=3.19.4
packaging>=21.3
filelock>=3.4.2
tqdm>=4.62.3
accelerate>=0.10.0
sentence-transformers
llama-cpp-python
#transformers['pytorch']
openai==0.28.1
langchain==0.0.316
langchain_community
#CUDACXX=/usr/local/cuda-11.8/bin/nvcc CMAKE_ARGS="-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade
google-generativeai
google-cloud-aiplatform